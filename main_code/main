import cv2
import torch
import numpy as np
from face_tracker import face_detection
import matplotlib.pyplot as plt
from joblib import load


# Load the trained model
def load_model(model_path):
    # Load the saved model
    loaded_model = load(model_path)
    return loaded_model


# Preprocess input image
def preprocess_frame(frame, weight_matrices, mean_matrices):
    if np.size(frame) != 2304:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert frame to grayscale
        frame = cv2.resize(frame, (48, 48))  # Resize frame to match input size used during training
    frame = frame.astype(np.float32) / 255.0
    # Ensure that the mean of the image is 0.5
    mean_pixel_value = np.mean(frame)
    frame -= (mean_pixel_value - 0.5)

    # Convert image back to uint8
    frame = (frame * 255).clip(0, 255).astype(np.uint8)
    frame = cv2.equalizeHist(frame)
    frame = frame / 255.0  # Normalize frame
    flattened_frame = frame.flatten()  # Flatten the frame into a vector

    # Initialize an empty list to store the processed vectors
    processed_vectors = []

    # Process emotions in the specified order
    emotions_order = ["happy", "angry", "surprised", "sad"]
    for emotion in emotions_order:
        # Subtract mean vector from flattened frame
        subtracted_vector = flattened_frame - mean_matrices[emotion]

        # Multiply by the weight matrix
        weighted_vector = np.dot(subtracted_vector, weight_matrices[emotion])

        # Append weighted vector to the list
        processed_vectors.append(weighted_vector)

    # Concatenate all the processed vectors
    concatenated_vector = np.hstack(processed_vectors)

    return concatenated_vector


# Perform prediction
def predict(model, vector):
    vector_tensor = torch.from_numpy(vector).view(1, -1)  # Convert vector to tensor
    output = model(vector_tensor.double())  # Forward pass
    _, predicted_label = torch.max(output.data, 1)  # Get predicted label
    return predicted_label.item()


# Main function
def main():
    weight_matrices = {}
    mean_matrices = {}
    weight_matrices['angry'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                       'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                       '/angry_matrix.npy')
    mean_matrices['angry'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                     'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                     '/angry_mean_matrix.npy')
    weight_matrices['happy'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                       'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                       '/happy_matrix.npy')
    mean_matrices['happy'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                     'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                     '/happy_mean_matrix.npy')
    weight_matrices['sad'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                     'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                     '/sad_matrix.npy')
    mean_matrices['sad'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                   'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                   '/sad_mean_matrix.npy')
    weight_matrices['surprised'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                           'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                           '/surprised_matrix.npy')
    mean_matrices['surprised'] = np.load('/Users/omerhazan/Desktop/personal/studies/image '
                                         'processing/image_processing_project/PCA/eigen_matrices/eigen_matrices_hand_picked'
                                         '/surprised_mean_matrix.npy')

    # Load the trained model
    emotion_classifier = load_model('/Users/omerhazan/Desktop/personal/studies/image '
                                    'processing/image_processing_project/PCA/trained_SVM_models/svm_model_0.5689.joblib')

    # Open video stream
    cap = cv2.VideoCapture(0)

    # Initialize variables for majority vote
    vote_history = []

    while True:
        ret, frame = cap.read()  # Read frame from video stream
        if not ret:
            break
        # todo: face detection code goes here
        faces, detected_positions = face_detection(frame)  # replace with face detection code
        if faces:
            for i, face in enumerate(faces):
                x, y, w, h = detected_positions[i]
                # Replace "YourTextHere" with text from your dictionary
                vector = preprocess_frame(face, weight_matrices, mean_matrices)
                predicted_label = emotion_classifier.predict(vector)
                vote_history.append(predicted_label)

                # Keep only the last 20 predictions in the vote history
                if len(vote_history) > 20:
                    vote_history.pop(0)

                # Count the occurrences of each label in the vote history
                votes_count = [vote_history.count(label) for label in range(4)]

                # Get the label with the highest count (majority vote)
                majority_vote = np.argmax(votes_count)

                # Map predicted label to actual class name
                class_names = {0: 'angry', 1: 'happy', 2: 'sad', 3: 'surprised'}
                font = cv2.FONT_HERSHEY_SIMPLEX
                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 255), 2)
                text = f"Prediction: {class_names[predicted_label[0]]}"
                cv2.putText(frame, text, (x, y - 10), font, 0.5, (255, 0, 255), 1, cv2.LINE_AA)


        # Store prediction in vote history


        # Display the majority vote prediction

        # Concatenate frames horizontally

        cv2.imshow('guess emotion', frame)

        plt.show()

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
